# NLP
Different traditional NLP approaches are 
- Linguistic Rules: These are manually created rules based on the structure and grammar of a language to process and understand text ( rule: a verb follows a noun).
- Handcrafted Features: Features manually designed by experts to capture important aspects of the text, such as word frequency or part-of-speech tags.
- Statistical Models: Models that use statistical methods to analyze and interpret text data. An example is the bag of words model, which represents a document as an unordered set of words, ignoring the order and structure of the words. It loses information about the order and context of words.
# NLP Libraries
- NLTK (Natural Language Toolkit): Foundational library for text processing tasks like tokenization, stemming, lemmatization, and stop word removal.
- spaCy: Similar to NLTK but optimized for performance and easier to use, especially for large datasets.
- Gensim: Focuses on topic modeling and document similarity, with some text pre-processing utilities.
- TextBlob: Offers core NLP functionalities and is simple to use, making it great for beginners.

For deep learning tasks in NLP:

- TensorFlow: Comprehensive framework supporting transformers.
- PyTorch: Easier to use than TensorFlow.
- MXNet and JAX: Moderate learning curve.
- Keras: Easiest to use among deep learning libraries.
